{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "from collections import  Counter\n",
    "plt.style.use('ggplot')\n",
    "stop=set(stopwords.words('english'))\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "import string\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\n",
    "from keras.initializers import Constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../train.csv')\n",
    "test = pd.read_csv('../test.csv')\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    \"\"\"Removes links and non-ASCII characters\"\"\"\n",
    "    \n",
    "    tweet = ''.join([x for x in tweet if x in string.printable])\n",
    "    \n",
    "    # Removing URLs\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n",
    "    \n",
    "    for p in punctuations:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "\n",
    "    text = text.replace('...', ' ... ')\n",
    "    \n",
    "    if '...' not in text:\n",
    "        text = text.replace('..', ' ... ')\n",
    "    \n",
    "    return text\n",
    "\n",
    "def convert_abbrev(word):\n",
    "    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word\n",
    "\n",
    "def convert_abbrev_in_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [convert_abbrev(word) for word in tokens]\n",
    "    text = ' '.join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_with_target_error = [328,443,513,2619,3640,3900,4342,5781,6552,6554,6570,6701,6702,6729,6861,7226]\n",
    "train.at[train['id'].isin(ids_with_target_error),'target'] = 0\n",
    "train[train['id'].isin(ids_with_target_error)]\n",
    "\n",
    "train = train.drop(train[train[\"text\"].duplicated()].index)\n",
    "\n",
    "with open('../abbreviation.json') as json_file:\n",
    "    abbreviations = json.load(json_file)\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: clean_tweets(x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: clean_tweets(x))\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: remove_emoji(x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: remove_emoji(x))\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: remove_punctuations(x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: remove_punctuations(x))\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: convert_abbrev_in_text(x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: convert_abbrev_in_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "embed = hub.Module('https://tfhub.dev/google/elmo/3', trainable=True)\n",
    "\n",
    "embeddings = embed(\n",
    "    np.array(train[\"text\"]),\n",
    "    signature=\"default\",\n",
    "    as_dict=True)[\"default\"]\n",
    "embeddings\n",
    "\n",
    "embeddings_test = embed(\n",
    "    np.array(test[\"text\"]),\n",
    "    signature=\"default\",\n",
    "    as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  sess.run(tf.tables_initializer())\n",
    "  x_test = sess.run(embeddings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x_test).to_csv(\"../elmo_emb_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_test = pd.read_csv('../elmo_emb_test.csv')\n",
    "emb_test\n",
    "\n",
    "emb_train = pd.read_csv('./elmo_emb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Need to clean \"train[label]\" for actual labels\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(emb_train, \n",
    "                                                  train[\"target\"],  \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.15)\n",
    "len_act = len(xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8547247767559643 0.8540356762645799\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(emb_train, train[\"target\"])\n",
    "\n",
    "full_predict_neigh = neigh.predict(emb_train)\n",
    "f1_scor = f1_score(train[\"target\"].values,full_predict_neigh,  average='micro')\n",
    "f1_scor_2 = f1_score(train[\"target\"].values, full_predict_neigh, average='weighted')\n",
    "print(f1_scor, f1_scor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7184724689165186 0.7182203029717853\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(xtrain, ytrain)\n",
    "\n",
    "predict_neigh = neigh.predict(xvalid)\n",
    "f1_scor = f1_score(yvalid, predict_neigh, average='micro')\n",
    "f1_scor_2 = f1_score(yvalid, predict_neigh, average='weighted')\n",
    "\n",
    "print(f1_scor, f1_scor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_predict_neigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851392776222844 0.8503097318927003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from itertools import product\n",
    "\n",
    "parameters = dict(\n",
    "    layers = [49, 50, 51],\n",
    "    iteration = [100, 300, 500],\n",
    "    lrs = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    ")\n",
    "param_values = [v for v in parameters.values()]\n",
    "\n",
    "f1_hist = []\n",
    "best_score = 0\n",
    "\n",
    "mlp_clf = MLPClassifier(50, learning_rate = \"constant\", max_iter=100, random_state = 42)\n",
    "mlp_clf.fit(xtrain, ytrain)\n",
    "\n",
    "elmo_result_train = mlp_clf.predict(emb_train)\n",
    "elmo_f1_sco_train = f1_score(elmo_result_train, train[\"target\"].values)\n",
    "\n",
    "full_predict_mlp = mlp_clf.predict(emb_train)\n",
    "f1_scor_mlp = f1_score(train[\"target\"].values,full_predict_mlp,  average='micro')\n",
    "f1_scor_2_mlp = f1_score(train[\"target\"].values, full_predict_mlp, average='weighted')\n",
    "\n",
    "print(f1_scor_mlp, f1_scor_2_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_result_test = mlp_clf.predict_proba(emb_test)\n",
    "pd.DataFrame(elmo_result_test).to_csv('../ELMo_test_proba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.199286e-04</td>\n",
       "      <td>0.999280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.309274e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.887770e-04</td>\n",
       "      <td>0.999811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.089702e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.617704e-04</td>\n",
       "      <td>0.999538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.315826e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.328398e-09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.193736e-03</td>\n",
       "      <td>0.998806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.795002e-05</td>\n",
       "      <td>0.999922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.591668e-05</td>\n",
       "      <td>0.999964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.553735e-04</td>\n",
       "      <td>0.999645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.615551e-04</td>\n",
       "      <td>0.999238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.924727e-04</td>\n",
       "      <td>0.999708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.644526e-06</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.005330e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.952901e-01</td>\n",
       "      <td>0.004710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.984738e-01</td>\n",
       "      <td>0.001526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.877934e-01</td>\n",
       "      <td>0.012207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.937986e-01</td>\n",
       "      <td>0.006201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.071589e-01</td>\n",
       "      <td>0.292841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.676696e-01</td>\n",
       "      <td>0.032330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.917162e-01</td>\n",
       "      <td>0.008284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.983235e-01</td>\n",
       "      <td>0.001676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.965015e-01</td>\n",
       "      <td>0.003499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.846813e-01</td>\n",
       "      <td>0.015319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.971646e-01</td>\n",
       "      <td>0.002835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9.819755e-01</td>\n",
       "      <td>0.018025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.996714e-01</td>\n",
       "      <td>0.000329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.996693e-01</td>\n",
       "      <td>0.000331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9.994746e-01</td>\n",
       "      <td>0.000525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7473</th>\n",
       "      <td>9.863922e-01</td>\n",
       "      <td>0.013608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>9.712947e-01</td>\n",
       "      <td>0.028705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7475</th>\n",
       "      <td>9.868485e-01</td>\n",
       "      <td>0.013152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7476</th>\n",
       "      <td>9.855160e-01</td>\n",
       "      <td>0.014484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477</th>\n",
       "      <td>9.946029e-01</td>\n",
       "      <td>0.005397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7478</th>\n",
       "      <td>2.711020e-03</td>\n",
       "      <td>0.997289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7479</th>\n",
       "      <td>9.524806e-01</td>\n",
       "      <td>0.047519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480</th>\n",
       "      <td>2.252368e-03</td>\n",
       "      <td>0.997748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7481</th>\n",
       "      <td>2.224089e-01</td>\n",
       "      <td>0.777591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7482</th>\n",
       "      <td>5.605970e-01</td>\n",
       "      <td>0.439403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7483</th>\n",
       "      <td>1.423259e-03</td>\n",
       "      <td>0.998577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7484</th>\n",
       "      <td>2.596989e-01</td>\n",
       "      <td>0.740301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7485</th>\n",
       "      <td>3.288419e-01</td>\n",
       "      <td>0.671158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7486</th>\n",
       "      <td>4.975053e-01</td>\n",
       "      <td>0.502495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>3.425705e-02</td>\n",
       "      <td>0.965743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7488</th>\n",
       "      <td>9.386244e-01</td>\n",
       "      <td>0.061376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7489</th>\n",
       "      <td>2.402617e-01</td>\n",
       "      <td>0.759738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>1.193523e-02</td>\n",
       "      <td>0.988065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7491</th>\n",
       "      <td>1.593646e-02</td>\n",
       "      <td>0.984064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>3.708489e-03</td>\n",
       "      <td>0.996292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>6.567737e-02</td>\n",
       "      <td>0.934323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7494</th>\n",
       "      <td>3.962464e-02</td>\n",
       "      <td>0.960375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>2.436524e-02</td>\n",
       "      <td>0.975635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>4.498325e-02</td>\n",
       "      <td>0.955017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>1.414235e-02</td>\n",
       "      <td>0.985858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>1.976393e-02</td>\n",
       "      <td>0.980236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>5.166211e-01</td>\n",
       "      <td>0.483379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7500</th>\n",
       "      <td>9.422392e-03</td>\n",
       "      <td>0.990578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7501</th>\n",
       "      <td>7.167140e-02</td>\n",
       "      <td>0.928329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7502</th>\n",
       "      <td>1.822570e-02</td>\n",
       "      <td>0.981774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7503 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1\n",
       "0     7.199286e-04  0.999280\n",
       "1     3.309274e-07  1.000000\n",
       "2     1.887770e-04  0.999811\n",
       "3     6.089702e-07  0.999999\n",
       "4     4.617704e-04  0.999538\n",
       "5     2.315826e-07  1.000000\n",
       "6     6.328398e-09  1.000000\n",
       "7     1.193736e-03  0.998806\n",
       "8     7.795002e-05  0.999922\n",
       "9     3.591668e-05  0.999964\n",
       "10    3.553735e-04  0.999645\n",
       "11    7.615551e-04  0.999238\n",
       "12    2.924727e-04  0.999708\n",
       "13    5.644526e-06  0.999994\n",
       "14    8.005330e-07  0.999999\n",
       "15    9.952901e-01  0.004710\n",
       "16    9.984738e-01  0.001526\n",
       "17    9.877934e-01  0.012207\n",
       "18    9.937986e-01  0.006201\n",
       "19    7.071589e-01  0.292841\n",
       "20    9.676696e-01  0.032330\n",
       "21    9.917162e-01  0.008284\n",
       "22    9.983235e-01  0.001676\n",
       "23    9.965015e-01  0.003499\n",
       "24    9.846813e-01  0.015319\n",
       "25    9.971646e-01  0.002835\n",
       "26    9.819755e-01  0.018025\n",
       "27    9.996714e-01  0.000329\n",
       "28    9.996693e-01  0.000331\n",
       "29    9.994746e-01  0.000525\n",
       "...            ...       ...\n",
       "7473  9.863922e-01  0.013608\n",
       "7474  9.712947e-01  0.028705\n",
       "7475  9.868485e-01  0.013152\n",
       "7476  9.855160e-01  0.014484\n",
       "7477  9.946029e-01  0.005397\n",
       "7478  2.711020e-03  0.997289\n",
       "7479  9.524806e-01  0.047519\n",
       "7480  2.252368e-03  0.997748\n",
       "7481  2.224089e-01  0.777591\n",
       "7482  5.605970e-01  0.439403\n",
       "7483  1.423259e-03  0.998577\n",
       "7484  2.596989e-01  0.740301\n",
       "7485  3.288419e-01  0.671158\n",
       "7486  4.975053e-01  0.502495\n",
       "7487  3.425705e-02  0.965743\n",
       "7488  9.386244e-01  0.061376\n",
       "7489  2.402617e-01  0.759738\n",
       "7490  1.193523e-02  0.988065\n",
       "7491  1.593646e-02  0.984064\n",
       "7492  3.708489e-03  0.996292\n",
       "7493  6.567737e-02  0.934323\n",
       "7494  3.962464e-02  0.960375\n",
       "7495  2.436524e-02  0.975635\n",
       "7496  4.498325e-02  0.955017\n",
       "7497  1.414235e-02  0.985858\n",
       "7498  1.976393e-02  0.980236\n",
       "7499  5.166211e-01  0.483379\n",
       "7500  9.422392e-03  0.990578\n",
       "7501  7.167140e-02  0.928329\n",
       "7502  1.822570e-02  0.981774\n",
       "\n",
       "[7503 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(elmo_result_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(elmo_result_train).to_csv('./ELMo_full_proba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score train :  0.8251450676982592\n",
      "f1 score valid :  0.7693989071038251\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(50, learning_rate = \"constant\", max_iter=100, random_state = 42)\n",
    "mlp_clf.fit(xtrain, ytrain)\n",
    "\n",
    "elmo_result_train = mlp_clf.predict(xtrain)\n",
    "elmo_f1_sco_train = f1_score(elmo_result_train, ytrain)\n",
    "\n",
    "elmo_result_valid = mlp_clf.predict(xvalid)\n",
    "elmo_f1_sco_valid = f1_score(elmo_result_valid, yvalid)\n",
    "\n",
    "print(\"f1 score train : \", elmo_f1_sco_train)\n",
    "print(\"f1 score valid : \", elmo_f1_sco_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_result_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train = emb_train.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 18463 is different from 1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-aa7d5a9d7497>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0melmo_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0melmo_f1_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melmo_result_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \"\"\"\n\u001b[1;32m    970\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    683\u001b[0m                                          layer_units[i + 1])))\n\u001b[1;32m    684\u001b[0m         \u001b[0;31m# forward propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, activations)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             activations[i + 1] = safe_sparse_dot(activations[i],\n\u001b[0;32m--> 104\u001b[0;31m                                                  self.coefs_[i])\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 18463 is different from 1024)"
     ]
    }
   ],
   "source": [
    "elmo_train = mlp_clf.predict(emb_train)\n",
    "elmo_f1_train = f1_score(elmo_result_train, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_corpus = train[\"text\"].tolist()\n",
    "list_labels = train[\"target\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, test_size=0.2, \n",
    "                                                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6002,)\n",
      "(6002, 18463)\n",
      "(1501,)\n",
      "(6002,)\n"
     ]
    }
   ],
   "source": [
    "def tfidf(data):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    print(np.shape(data))\n",
    "    train = tfidf_vectorizer.fit_transform(data)\n",
    "    print(np.shape(train))\n",
    "    return train, tfidf_vectorizer\n",
    "\n",
    "X_train_tfidf, tfidf_vectorizer = tfidf(X_train)\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6002x18463 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 87833 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score train :  0.9445568595710239\n",
      "f1 score valid :  0.7421276595744681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(30, learning_rate = \"constant\", max_iter=8, random_state = 42)\n",
    "mlp_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "tfidf_result_train = mlp_clf.predict(X_train_tfidf)\n",
    "tfidf_f1_sco_train = f1_score(tfidf_result_train, y_train)\n",
    "\n",
    "tfidf_result_valid = mlp_clf.predict(X_test_tfidf)\n",
    "tfidf_f1_sco_valid = f1_score(tfidf_result_valid, y_test)\n",
    "\n",
    "print(\"f1 score train : \", tfidf_f1_sco_train)\n",
    "print(\"f1 score valid : \", tfidf_f1_sco_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
